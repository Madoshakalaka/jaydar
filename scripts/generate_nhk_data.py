#!/usr/bin/env python3
"""Generate Rust code with embedded NHK pitch accent data."""

import json
from collections import defaultdict

def generate_rust_code():
    with open('nhk_16_entries.json', 'r') as f:
        data = json.load(f)
    
    # Build a mapping from (kana, kanji) to pitch accent
    pitch_data = {}
    
    for entry in data:
        kana = entry['kana']
        kanji_list = entry.get('kanji', [])
        
        # Get pitch accent (use first one if multiple)
        if entry['accents'] and entry['accents'][0]['accent']:
            pitch = entry['accents'][0]['accent'][0]['pitchAccent']
        else:
            continue  # Skip entries without pitch data
        
        # Store pitch for kana-only entries
        if not kanji_list:
            pitch_data[(kana, kana)] = pitch
        else:
            # Store pitch for each kanji
            for kanji in kanji_list:
                pitch_data[(kana, kanji)] = pitch
    
    # Generate Rust code with phf for compile-time hash map
    rust_code = '''// Auto-generated NHK pitch accent data
// DO NOT EDIT - this file is generated by scripts/generate_nhk_data.py

use phf::phf_map;

static NHK_PITCH_DATA: phf::Map<&'static str, u8> = phf_map! {
'''
    
    # Add entries to the map
    # Use combined key to avoid tuple issues
    for (kana, kanji), pitch in sorted(pitch_data.items()):
        # Escape quotes in the strings
        kana_escaped = kana.replace('"', r'\"')
        kanji_escaped = kanji.replace('"', r'\"')
        key = f"{kana_escaped}\t{kanji_escaped}"
        rust_code += f'    "{key}" => {pitch},\n'
    
    rust_code += '''};

/// Get pitch accent for a word given its reading and text
pub fn get_pitch_accent(reading: &str, text: &str) -> Option<u8> {
    let key = format!("{}\t{}", reading, text);
    NHK_PITCH_DATA.get(key.as_str()).copied()
}
'''
    
    # Write to file
    with open('src/nhk_data.rs', 'w') as f:
        f.write(rust_code)
    
    print(f"Generated Rust code with {len(pitch_data)} pitch accent entries")
    print(f"Saved to src/nhk_data.rs")
    
    # Show some statistics
    kana_counts = defaultdict(int)
    for (kana, _), _ in pitch_data.items():
        kana_counts[kana] += 1
    
    # Find most represented readings
    top_readings = sorted(kana_counts.items(), key=lambda x: x[1], reverse=True)[:10]
    print("\nTop 10 readings by number of entries:")
    for kana, count in top_readings:
        print(f"  {kana}: {count} entries")

if __name__ == "__main__":
    generate_rust_code()