#!/usr/bin/env python3
"""Generate Rust code with NHK data supporting multiple pitch accents per word."""

import json
from collections import defaultdict

def generate_rust_code():
    # Load NHK data
    with open('nhk_16_entries.json', 'r') as f:
        data = json.load(f)
    
    # Build a mapping from (kana, kanji) to list of pitch accents
    pitch_data = {}
    reading_counts = defaultdict(int)
    
    # First pass: count readings
    for entry in data:
        kana = entry['kana']
        reading_counts[kana] += 1
    
    # Second pass: collect all pitch accents for each word
    included_count = 0
    for entry in data:
        kana = entry['kana']
        
        # Skip rare readings
        if reading_counts[kana] < 2:
            continue
            
        kanji_list = entry.get('kanji', [])
        
        # Collect all pitch accents from all accent groups
        pitches = []
        for accent_group in entry.get('accents', []):
            for accent in accent_group.get('accent', []):
                pitch = accent.get('pitchAccent')
                if pitch is not None and pitch not in pitches:
                    pitches.append(pitch)
        
        if not pitches:
            continue
        
        # Store pitches for kana-only entries
        if not kanji_list:
            pitch_data[(kana, kana)] = pitches
            included_count += 1
        else:
            # Store pitches for each kanji
            for kanji in kanji_list:
                pitch_data[(kana, kanji)] = pitches
                included_count += 1
    
    print(f"Including {included_count} entries (from {len(data)} total)")
    
    # Generate Rust code with static array for better performance
    rust_code = '''// Auto-generated NHK pitch accent data with multiple pitch support
// DO NOT EDIT - this file is generated by scripts/generate_nhk_data_multi_pitch.py

/// Pitch accent data as (reading, text, pitches) tuples
static NHK_PITCH_DATA: &[(&str, &str, &[u8])] = &[
'''
    
    # Add entries as array elements
    for (kana, kanji), pitches in sorted(pitch_data.items()):
        pitch_str = ', '.join(str(p) for p in pitches)
        rust_code += f'    ("{kana}", "{kanji}", &[{pitch_str}]),\n'
    
    rust_code += '''];

/// Get pitch accents for a word given its reading and text
pub fn get_pitch_accents(reading: &str, text: &str) -> Vec<u8> {
    NHK_PITCH_DATA
        .iter()
        .find(|(r, t, _)| *r == reading && *t == text)
        .map(|(_, _, pitches)| pitches.to_vec())
        .unwrap_or_default()
}

/// Get pitch accent for a word (returns first/primary pitch)
pub fn get_pitch_accent(reading: &str, text: &str) -> Option<u8> {
    get_pitch_accents(reading, text).first().copied()
}
'''
    
    # Write to file
    with open('src/nhk_data.rs', 'w') as f:
        f.write(rust_code)
    
    print(f"Generated Rust code with {len(pitch_data)} pitch accent entries")
    print(f"Saved to src/nhk_data.rs")
    
    # Show some examples with multiple pitches
    print("\nExamples of words with multiple pitch accents:")
    count = 0
    for (kana, kanji), pitches in sorted(pitch_data.items()):
        if len(pitches) > 1:
            print(f"  {kanji} ({kana}): {pitches}")
            count += 1
            if count >= 10:
                break

if __name__ == "__main__":
    generate_rust_code()